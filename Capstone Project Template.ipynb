{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The goal of this project is to create a data warehouse for immigration using I94 Immigration Data, World Temperature Data, U.S. City Demographic Data, and Airport Code Table.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import timedelta, date\n",
    "from pyspark.sql.functions import year, udf, col\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField, DateType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "I will create 1 fact table(immigration) and 2 dimension table(temperature and cities). I will use spark.\n",
    "\n",
    "#### Describe and Gather Data\n",
    "##### I94 Immigration Data \n",
    "- cicid\n",
    "- i94yr\n",
    "- i94mon\n",
    "- i94cit\n",
    "- other immigration columns.\n",
    "\n",
    "##### World Temperature Data\n",
    "- dt\n",
    "- average temperature\n",
    "- average temperature uncertainty\n",
    "- city\n",
    "- country\n",
    "- latitude\n",
    "- longitude\n",
    "\n",
    "##### Airport Code Table\n",
    "- ident\n",
    "- type\n",
    "- name\n",
    "- elevation ft\n",
    "- continent\n",
    "- iso country\n",
    "- iso region\n",
    "- municipality\n",
    "- gps code\n",
    "- iata code\n",
    "- local code\n",
    "- coordinates\n",
    "\n",
    "##### City Demographic Data\n",
    "- city\n",
    "- state\n",
    "- median age\n",
    "- male population\n",
    "- female population\n",
    "- total ppulation\n",
    "- number of veterans\n",
    "- foreign born\n",
    "- average household size\n",
    "- state code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_df = spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df = spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df = spark.read.csv('airport-codes_csv.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cities_df = spark.read.option(\"delimiter\", \";\").csv('us-cities-demographics.csv', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data & Cleaing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     F|  null|     DL|9.495645143E10|00040|      B1|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1988.0|10292016|     M|  null|     DL|9.495638813E10|00040|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "i94cit, i94port are just code. The origin data is in I94_SAS_Labels_Descriptions.SAS. <br>\n",
    "Arrdate is SAS date foramt.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_df.filter(i94_df.i94cit.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_df.filter(i94_df.arrdate.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Latitude|\n",
      "+--------+\n",
      "|  36.17N|\n",
      "|  44.20N|\n",
      "|  57.05N|\n",
      "|   4.02S|\n",
      "|  24.92N|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.select(\"Latitude\").distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data include many countries. I remove other countries without US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             Country|\n",
      "+--------------------+\n",
      "|                Chad|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|               Yemen|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|              Guyana|\n",
      "|               Burma|\n",
      "|         Philippines|\n",
      "|             Eritrea|\n",
      "|            Djibouti|\n",
      "|            Malaysia|\n",
      "|           Singapore|\n",
      "|              Turkey|\n",
      "|              Malawi|\n",
      "|                Iraq|\n",
      "|             Germany|\n",
      "|         Afghanistan|\n",
      "|            Cambodia|\n",
      "|              Jordan|\n",
      "|              Rwanda|\n",
      "|               Sudan|\n",
      "|              France|\n",
      "|              Greece|\n",
      "|           Sri Lanka|\n",
      "|              Taiwan|\n",
      "|             Algeria|\n",
      "|   Equatorial Guinea|\n",
      "|                Togo|\n",
      "|            Slovakia|\n",
      "|             Reunion|\n",
      "|           Argentina|\n",
      "|             Belgium|\n",
      "|              Angola|\n",
      "|             Ecuador|\n",
      "|               Qatar|\n",
      "|             Lesotho|\n",
      "|          Madagascar|\n",
      "|             Albania|\n",
      "|             Finland|\n",
      "|               Ghana|\n",
      "|           Nicaragua|\n",
      "|               Benin|\n",
      "|                Peru|\n",
      "|        Sierra Leone|\n",
      "|               China|\n",
      "|       United States|\n",
      "|               India|\n",
      "|             Bahamas|\n",
      "|             Belarus|\n",
      "|             Somalia|\n",
      "|               Chile|\n",
      "|         Puerto Rico|\n",
      "|          Tajikistan|\n",
      "|             Croatia|\n",
      "|             Burundi|\n",
      "|             Nigeria|\n",
      "|             Bolivia|\n",
      "|               Gabon|\n",
      "|               Italy|\n",
      "|            Suriname|\n",
      "|           Lithuania|\n",
      "|        Turkmenistan|\n",
      "|              Norway|\n",
      "|               Spain|\n",
      "|                Cuba|\n",
      "|          Mauritania|\n",
      "|             Denmark|\n",
      "|Central African R...|\n",
      "|               Niger|\n",
      "|          Bangladesh|\n",
      "|                Iran|\n",
      "|             Ireland|\n",
      "|               Congo|\n",
      "|            Thailand|\n",
      "|           Swaziland|\n",
      "|                Laos|\n",
      "|             Morocco|\n",
      "|              Panama|\n",
      "|           Hong Kong|\n",
      "|           Venezuela|\n",
      "|             Ukraine|\n",
      "|              Israel|\n",
      "|             Iceland|\n",
      "|                Oman|\n",
      "|         South Korea|\n",
      "|              Cyprus|\n",
      "|             Uruguay|\n",
      "|              Mexico|\n",
      "|            Zimbabwe|\n",
      "|          Montenegro|\n",
      "|             Estonia|\n",
      "|             Georgia|\n",
      "|           Indonesia|\n",
      "|       Côte D'Ivoire|\n",
      "|           Guatemala|\n",
      "|            Mongolia|\n",
      "|               Libya|\n",
      "|          Azerbaijan|\n",
      "|             Armenia|\n",
      "+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.select('Country').distinct().show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df = temp_df.filter(temp_df.Country == 'United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "I desinged data warehouse, and fact data is immigration data.<br>\n",
    "This data and fact data do not have and can not extract same key. So I discard this data. (Fact data just have airline. I can not guess airport.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "##### Fact Table (immigration)\n",
    "- id: pk\n",
    "- arrive_date: us arrive date\n",
    "- birth_year: birth year\n",
    "- addr: addres\n",
    "- gender\n",
    "- admission number: US Admission Number\n",
    "- visa_type\n",
    "- year: immigration year\n",
    "- month: immigration month\n",
    "- cit: immigration cit\n",
    "- port_city: immigration port city\n",
    "- post_state: immigration port state\n",
    "- mode: immigration mode (1(air), 2(sea), 3(land), 9(not reported))\n",
    "- visa: 1(Business), 2(Pleasure), 3(Student)\n",
    "\n",
    "#### Dimension Table 1 (temperature)\n",
    "- id: pk\n",
    "- year\n",
    "- average_temperature\n",
    "- average_temperature_uncertainty\n",
    "- city\n",
    "- latitude\n",
    "- longitude\n",
    "\n",
    "#### Dimension Table 2 (cities)\n",
    "- id: pk\n",
    "- city\n",
    "- state\n",
    "- median age\n",
    "- male population\n",
    "- female population\n",
    "- total population\n",
    "- number of veterans\n",
    "- foreign born\n",
    "- average household size\n",
    "- state code\n",
    "- race\n",
    "- count\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "##### immigration\n",
    "1. To get cit, port and addr, parsing sas code file.\n",
    "2. Inner join origin immigration data.\n",
    "3. Select target columns and str columns lower some uppser case.\n",
    "\n",
    "##### temperature\n",
    "1. To get year, parsing date.\n",
    "2. Select target columns and str columns lower some uppser case.\n",
    "\n",
    "##### cities\n",
    "1. Select target columns and str columns lower some uppser case.\n",
    "\n",
    "And this notebook just insert 100 data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://student:student@localhost:5432/studentdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "sas_date_to_timestamp = udf(lambda x: timedelta(days=x) + date(1960, 1, 1), DateType())\n",
    "i94_df = i94_df.withColumn('arrive_date', sas_date_to_timestamp(col('arrdate')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    descriptions = f.readlines()\n",
    "    \n",
    "def extract_code(codes):\n",
    "    temp = []\n",
    "    for code in codes:\n",
    "        code = code.strip().replace(\"'\", '').split('=')\n",
    "        code = [c.strip() for c in code]\n",
    "        temp.append(code)\n",
    "    return pd.DataFrame(temp)\n",
    "\n",
    "cits = descriptions[10:298]\n",
    "cit_pd_df = extract_code(cits)\n",
    "cit_pd_df.columns = ['i94cit', 'cit']\n",
    "# print(cit_pd_df['i94cit'])\n",
    "cit_pd_df['i94cit'] = cit_pd_df['i94cit'].astype('int')\n",
    "schema = StructType([StructField('i94cit', IntegerType(), True),\n",
    "                     StructField('cit', StringType(), True)])\n",
    "cit_df = spark.createDataFrame(cit_pd_df,schema=schema)\n",
    "\n",
    "ports = descriptions[303:962]\n",
    "port_pd_df = extract_code(ports)\n",
    "port_pd_df.columns = ['i94port', 'port']\n",
    "\n",
    "port_pd_df['port_city'] = port_pd_df.port.str.split(',').str[0]\n",
    "port_pd_df['port_state'] = port_pd_df.port.str.split(',').str[1]\n",
    "port_pd_df = port_pd_df.drop(columns=['port'])\n",
    "schema = StructType([StructField('i94port', StringType(), True),\n",
    "                     StructField('port_city', StringType(), True),\n",
    "                     StructField('port_state', StringType(), True)])\n",
    "port_df = spark.createDataFrame(port_pd_df,schema=schema)\n",
    "\n",
    "addrs = descriptions[982:1036]\n",
    "addr_pd_df = extract_code(addrs)\n",
    "addr_pd_df.columns = ['i94addr', 'addr']\n",
    "\n",
    "schema = StructType([StructField('i94addr', StringType(), True),\n",
    "                     StructField('addr', StringType(), True)])\n",
    "addr_df = spark.createDataFrame(addr_pd_df,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_result_df = i94_df.join(cit_df, 'i94cit') \\\n",
    "    .join(port_df, 'i94port') \\\n",
    "    .join(addr_df, 'i94addr') \\\n",
    "    .select(col('arrive_date'),\n",
    "            col('biryear').alias('birth_year'),\n",
    "            col('addr'),\n",
    "            col('gender'),\n",
    "            col('admnum').alias('admission_number'),\n",
    "            col('visatype').alias('visa_type'),\n",
    "            col('i94yr').alias('year'),\n",
    "            col('i94mon').alias('month'),\n",
    "            col('cit'),\n",
    "            col('port_city'),\n",
    "            col('port_state'),\n",
    "            col('i94mode').alias('mode'),\n",
    "            col('i94visa').alias('visa')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_result_df['id'] = pd.RangeIndex(i94_result_df.shape[0])\n",
    "i94_result_df[['cit', 'port_city', 'port_state']] = i94_result_df[['cit', 'port_city', 'port_state']].apply(lambda col: col.str.lower())\n",
    "i94_result_df.head(100).to_sql('immigration', engine, if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_result_df = temp_df.withColumn('year', year(col('dt'))).select(\n",
    "    col('year'),\n",
    "    col('AverageTemperature').alias('average_temperature'),\n",
    "    col('AverageTemperatureUncertainty').alias('average_temperature_uncertainty'),\n",
    "    col('City').alias('city'),\n",
    "    col('Latitude').alias('latitude'),\n",
    "    col('Longitude').alias('longitude')\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_result_df['id'] = pd.RangeIndex(temp_result_df.shape[0])\n",
    "temp_result_df[['city']] = temp_result_df[['city']].apply(lambda col: col.str.lower())\n",
    "temp_result_df.head(100).to_sql('temperature', engine, if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cities_result_df = cities_df.select(\n",
    "    col('City').alias('city'),\n",
    "    col('State').alias('state'),\n",
    "    col('Median Age').alias('median_age'),\n",
    "    col('Male Population').alias('male_population'),\n",
    "    col('Female Population').alias('female_population'),\n",
    "    col('Total Population').alias('total_population'),\n",
    "    col('Number of Veterans').alias('number_of_veterans'),\n",
    "    col('Foreign-born').alias('foreign_born'),\n",
    "    col('Average Household Size').alias('average_household_size'),\n",
    "    col('State Code').alias('state_code'),\n",
    "    col('Race').alias('race'),\n",
    "    col('Count').alias('count')\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cities_result_df['id'] = pd.RangeIndex(cities_result_df.shape[0])\n",
    "cities_result_df[['city', 'state']] = cities_result_df[['city', 'state']].apply(lambda col: col.str.lower())\n",
    "cities_result_df.head(100).to_sql('cities', engine, if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Check the number of data is 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_check_df = pd.read_sql_query('select * from \"immigration\"',con=engine)\n",
    "if immigration_check_df.shape[0] != 100:\n",
    "    print('data size is error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_check_df = pd.read_sql_query('select * from \"temperature\"',con=engine)\n",
    "if temperature_check_df.shape[0] != 100:\n",
    "    print('data size is error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cities_check_df = pd.read_sql_query('select * from \"cities\"',con=engine)\n",
    "if cities_check_df.shape[0] != 100:\n",
    "    print('data size is error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "##### Fact Table (immigration)\n",
    "- id: pk\n",
    "- arrive_date: us arrive date\n",
    "- birth_year: birth year\n",
    "- addr: addres\n",
    "- gender\n",
    "- admission number: US Admission Number\n",
    "- visa_type\n",
    "- year: immigration year\n",
    "- month: immigration month\n",
    "- cit: immigration cit\n",
    "- port_city: immigration port city\n",
    "- post_state: immigration port state\n",
    "- mode: immigration mode (1(air), 2(sea), 3(land), 9(not reported))\n",
    "- visa: 1(Business), 2(Pleasure), 3(Student)\n",
    "\n",
    "#### Dimension Table 1 (temperature)\n",
    "- id: pk\n",
    "- year\n",
    "- average_temperature\n",
    "- average_temperature_uncertainty\n",
    "- city\n",
    "- latitude\n",
    "- longitude\n",
    "\n",
    "#### Dimension Table 2 (cities)\n",
    "- id: pk\n",
    "- city\n",
    "- state\n",
    "- median age\n",
    "- male population\n",
    "- female population\n",
    "- total population\n",
    "- number of veterans\n",
    "- foreign born\n",
    "- average household size\n",
    "- state code\n",
    "- race\n",
    "- count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "I use apache spark and pandas dataframe. \n",
    "1. Some data volume is big.<br>\n",
    "2. If data size is bigger than now, I can easily add other machine or customize spark application.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "Fact table have i94 year and month, So I often update month.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "   - I can use cloud service like aws. Cloud services usually offer scale out.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "   - I can use airflow or other CI tools(jenkins, etc). This tools offer schedule.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "   - I will add slave database. 100+ is not huge. So I think slave machine is enough.\n",
    "   - However, if the growth trend is steep or concentrated only in some time, I will use the cloud service(like redshift)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
